# ===================================================================
# Spring Boot configuration.
#
# This configuration will be overridden by the Spring profile you use,
# for example application-dev.yml if you use the "dev" profile.
#
# Full reference for Standard Spring Boot properties is available at:
# http://docs.spring.io/spring-boot/docs/current/reference/html/common-application-properties.html
# ===================================================================
# set -Dspring.profiles.active=<dev|sit|int> as JVM argument to run in desired profile
# If no profile is specified explicitly, application will fall back to default profile, which is "local"

spring:
  application:
    name: spark-job-service
#  autoconfigure:
#    exclude: org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration
  devtools:
    add-properties: false
    restart:
      enabled: false
      exclude: logs/*,application.log,*.log,*.log.*
  main:
    log-startup-info: true
  mvc:
    pathmatch:
      matching-strategy: ant-path-matcher
    problemdetails:
      enabled: true
  threads:
    virtual:
      enabled: true

#------------------------- Swagger configuration -------------------------
springdoc:
  show-actuator: true
  group-configs:
    -
      group: actuator
      display-name: Actuator
      paths-to-match: /actuator/**
    -
      group: sparkjob
      display-name: Spark Job
      paths-to-match: /**/spark-jobs/**
  swagger-ui:
    syntaxHighlight:
      activated: true

#------------------------- Actuators configuration -------------------------
# If not specified '/actuator' is taken as default. If specified must start with '/'
#management.endpoints.web.base-path=/
# Set it as "*", if you want to expose all actuator endpoints
management:
  endpoint:
    health:
      probes:
        enabled: true
  endpoints:
    web:
      exposure:
        include: "*"
  observations:
    key-values:
      application: ${spring.application.name}

server:
  port: 8090
  forward-headers-strategy: framework
#  servlet:
#      context-path:
logging:
  level:
    ROOT: info
    '[org.mongodb.driver]': warn
debug: false

# ===================================================================
# Application specific properties
# Add your own application properties here
# ===================================================================

#------------------------- Spark configurations -------------------------
spark:
  master: k8s://https://kubernetes.default.svc
  executor:
    instances: 2
    memory: 2g
    cores: 2
  driver:
    memory: 2g
    cores: 2
    extraJavaOptions: >
      -DMONGODB_URL=${MONGODB_URL:mongodb://localhost:27017}
      -DMONGO_FEATURE_DB=${MONGO_FEATURE_DB:feature-repo}
      -DSPARK_OUTPUT_PATH=${SPARK_OUTPUT_PATH:gs://fetch-bucket/spark-output}
      -DSTATEMENT_JOB_IMAGE=${PRE_PROCESSOR_JOB_IMAGE:spark-statement-job:0.0.1}
      -DWORD_COUNT_JOB_IMAGE=${WORD_COUNT_JOB_IMAGE:spark-word-count-job:0.0.1}
  kubernetes:
    namespace: spark
    authenticate.driver.serviceAccountName: spark
    driverEnv:
      SPARK_USER: spark
    #Always, Never, and IfNotPresent
#    container.image.pullPolicy: IfNotPresent
  submit.deployMode: cluster

#------------------------- Spark Submit Job configurations -------------------------
spark-submit:
  capture-job-logs: false
  jobs:
    spark-statement-job:
      main-class-name: com.ksoot.spark.statement.SparkStatementJob
      jar-file: local:///opt/spark/job-apps/spark-statement-job.jar
      conf:
        spark.kubernetes.container.image: ${STATEMENT_JOB_IMAGE:spark-statement-job:0.0.1}
    spark-word-count-job:
      main-class-name: com.ksoot.spark.wordcount.SparkWordCountJob
      jar-file: local:///opt/spark/job-apps/spark-word-count-job.jar
      conf:
        spark.kubernetes.container.image: ${WORD_COUNT_JOB_IMAGE:spark-word-count-job:0.0.1}